{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Repetition\n",
    "✅ Kernel (Filter): Small matrix that slides over the input, detecting patterns.\n",
    "✅ Feature Map: Output of a kernel applied to the input, highlighting detected features.\n",
    "✅ Convolutional Layer: Applies multiple kernels to the same input, generating multiple feature maps.\n",
    "✅ No Chain Reaction: Each kernel processes the input independently; outputs are not reused within the same layer.\n",
    "✅ Next Layer Input: All feature maps from one layer serve as input for the next.\n",
    "✅ Deeper Layers: Extract more abstract patterns (edges → textures → shapes → objects).\n",
    "\n",
    "Handling Multiple Feature Maps Across Layers:\n",
    "✅ Each filter in a new convolutional layer processes all feature maps from the previous layer at once.\n",
    "✅ Filters in deeper layers are three-dimensional, spanning across all feature maps of the previous layer.\n",
    "✅ Instead of individually convolving each feature map with each filter, the entire set of previous feature maps is processed together per filter.\n",
    "✅ This method captures complex spatial and hierarchical relationships while keeping computations manageable.\n",
    "\n",
    "## LeNet-5 \n",
    "- 1998\n",
    "- Handwriting recognition in postal services and banking.\n",
    "- Object and face recognition in images and videos.\n",
    "- Autonomous driving systems for recognizing and interpreting road signs.\n",
    "- basic structure: pooling layer on top of each convolutional layer\n",
    "- today: \n",
    "  - Activation function: Relu instead of tanh\n",
    "  - Softmax instead of RBF\n",
    "\n",
    "## AlexNet\n",
    "- won 2021 ILSVRC challenge\n",
    "- top five error rate 17%\n",
    "- similiar to LeNet-5 but much larger and deeper\n",
    "- novelty: \n",
    "  - convolutional layers on top of each other\n",
    "  - reduce overfitting by: \n",
    "    - dropout 50% during training on F9 F10\n",
    "    - data augmentation: offset, flipping, lighting\n",
    "\n",
    "## GoogLeNet\n",
    "- won 2024 ILSVRC challenge\n",
    "- top five error rate 7%\n",
    "- novelty:\n",
    "    - much deeper possible by to inception modules\n",
    "      - 10 times fewer params then AlexNet (6 millions instead of 60 millions)\n",
    "      - inception modules:\n",
    "        - Block consisting of a sub cnn structure\n",
    "        - depth concatenation layer (Keras Concatenate axis=-1)\n",
    "        - 1 x 1 kernel layers involved\n",
    "          - not spatial but accross channel pattern sensetivity\n",
    "          - fewer feature map outputs then unput (bottleneck layers), speeds up, improve generalization\n",
    "          - capable of captureing more complex patterns due to small single cnn layers\n",
    "\n",
    "## VGGNet (Visual Geometry Group)\n",
    "- second place ILSVRC challenge 2014\n",
    "- Oxford\n",
    "- very simpole and classic\n",
    "- 2/3 cnn layer then pooling then again 2/3 cnn layer and pooling ... up to 19 cnn layers!\n",
    "- small 3x3 filters but many\n",
    "\n",
    "## ResNET (Residual Network)\n",
    "- ILSVRC 2015 winner\n",
    "- top five error rate 3.6%\n",
    "- extreme deep cnn 152 layers\n",
    "- trend:\n",
    "  - deeper nets with fewer params\n",
    "- novelty:\n",
    "  - shortcut connections:\n",
    "    - signal feeding into layer also added to the output layer\n",
    "    - called residual learning\n",
    "    - great when target function is close to identity function (often the case)\n",
    "    - progress even when several layers not started learning\n",
    "    - stack of Residual Units RU\n",
    "- many options like ResNet 34 or ResNet 152\n",
    "\n",
    "## Xception\n",
    "- based on GoogLeNet architecture\n",
    "- 2016\n",
    "- Outperformed Inception-v3\n",
    "- novelty:\n",
    "  - merges ideas of GoogLeNet and ResNet\n",
    "  - replaces inception modules with depthwise seperable convolutional layer\n",
    "  - used before but here its central\n",
    "  - Idea behindet seperable covolutional layers:\n",
    "    - regular convolutional layer:\n",
    "      - simultaneaously spatial (e.g. oval) and cross-channel patterns (mouth + nose + eyes = face)\n",
    "    - assumption: spatial and cross-channel patterns can be modeled seperatly\n",
    "      - 1. part single spatial filter\n",
    "      - 2. part looks fpor cross-channel patterns ( regular convolutional layer with 1x1 kernel)\n",
    "\n",
    "## SENet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
